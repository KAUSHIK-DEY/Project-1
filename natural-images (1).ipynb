{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense,Conv2D,MaxPooling2D,BatchNormalization,Dropout,Flatten\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import Adam, RMSprop\nimport keras\nimport cv2\nfrom keras import backend as K\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(x,path,y,value=0):\n    for i in os.listdir(path):\n        image_path=path+\"/\"+i\n        image=cv2.imread(image_path,0)\n        image=cv2.resize(image,(200,200),interpolation=cv2.INTER_CUBIC)\n        image=cv2.GaussianBlur(image,(5,5),cv2.BORDER_DEFAULT)\n        x.append(image) \n        y.append(value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plt_dynamic(x,vy,ty,ax,label1='Validation_loss',label2='Train_loss'):\n    ax.plot(x,vy,'b',label=label1)\n    ax.plot(x,ty,'r',label=label2)\n    plt.legend()\n    plt.grid()\n    fig.canvas.draw()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patha='../input/natural-images/natural_images/airplane'\npathc='../input/natural-images/natural_images/car'\npathca='../input/natural-images/natural_images/cat'\npathd='../input/natural-images/natural_images/dog'\npathf='../input/natural-images/natural_images/flower'\npathfr='../input/natural-images/natural_images/fruit'\npathm='../input/natural-images/natural_images/motorbike'\npathp='../input/natural-images/natural_images/person'\ny=[]\nx=[]\npreprocessing(x,patha,y,0)\npreprocessing(x,pathc,y,1)\npreprocessing(x,pathca,y,2)\npreprocessing(x,pathd,y,3)\npreprocessing(x,pathf,y,4)\npreprocessing(x,pathfr,y,5)\npreprocessing(x,pathm,y,6)\npreprocessing(x,pathp,y,7)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=np.array(x)\nprint(x.shape)\ny=np.array(y)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x,y=shuffle(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_1,x_test,y_1,y_test=train_test_split(x,y,test_size=0.3,shuffle=False)\nx_tr,x_cv,y_tr,y_cv=train_test_split(x_1,y_1,test_size=0.005,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,5):\n    plt.title(y[i])\n    plt.imshow(x_tr[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_cv.shape)\nprint(x_tr.shape)\nprint(x_test.shape)\nprint(y_tr.shape)\nprint(y_test.shape)\nprint(y_cv.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tr=x_tr/255\nx_test=x_test/255\nx_cv=x_cv/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows,img_cols=200,200\nif K.image_data_format() == 'channels_first':\n    x_tr= x_tr.reshape(x_tr.shape[0],1,img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    x_cv = x_cv.reshape(x_cv.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_tr= x_tr.reshape(x_tr.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    x_cv = x_cv.reshape(x_cv.shape[0],img_rows, img_cols,1)\n    input_shape = (img_rows, img_cols, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_tr=keras.utils.to_categorical(y_tr,8)\ny_test=keras.utils.to_categorical(y_test,8)\ny_cv=keras.utils.to_categorical(y_cv,8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range = 30,  \n        zoom_range = 0.2,  \n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip = True,  \n        vertical_flip=False)  \n\n\ndatagen.fit(x_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def structure(activation='relu',dropout=0.4,kernel='glorot_uniform'):\n    numclasses=8\n    model=Sequential()\n    model.add(Conv2D(32,kernel_size=(3,3),activation=activation,input_shape=input_shape,kernel_initializer=kernel))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Conv2D(64,(3,3),activation=activation,kernel_initializer=kernel))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3),activation=activation,kernel_initializer=kernel))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Conv2D(256,(3,3),activation=activation,kernel_initializer=kernel))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(256,(3,3),activation=activation,kernel_initializer=kernel))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(dropout))\n    model.add(Flatten())\n    model.add(Dense(128,activation=activation))\n    model.add(Dropout(dropout))\n    model.add(BatchNormalization())\n    model.add(Dense(64,activation=activation))\n    model.add(Dropout(dropout))\n    model.add(Dense(numclasses,activation='softmax'))\n    return model;  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=structure()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\nhistory=model.fit(datagen.flow(x_tr,y_tr,batch_size=16),epochs=25,verbose=1,validation_data=datagen.flow(x_cv,y_cv),callbacks = [learning_rate_reduction])\nscore=model.evaluate(x_test,y_test,verbose=0)\nprint('Test loss:',score[0])\nprint(\"Test accuracy:\",score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score=model.evaluate(x_test,y_test,verbose=0)\nprint('Test_score',score[0])\nprint('Test_accuracy',score[1])\n\nfig,ax=plt.subplots(1,1)\nax.set_xlabel('epoch')\nax.set_ylabel('categorical_cross_entropy')\n\nx=list(range(1,25+1))\nvy=history.history['val_loss']\nty=history.history['loss']\nplt_dynamic(x,vy,ty,ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,1)\nax.set_xlabel('epoch')\nax.set_ylabel('accuracy')\n\nx=list(range(1,25+1))\nty=history.history['accuracy']\nvy=history.history['val_accuracy']\nplt_dynamic(x,vy,ty,ax,label2='train_accuracy',label1='val_accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\nprediction=model.predict_classes(x_test)\ny_test=np.argmax(y_test,axis=-1)\ncm=confusion_matrix(y_test,prediction)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"json_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n \n# evaluate loaded model on test data\nloaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\nscore = loaded_model.evaluate(x_test,y_test, verbose=0)\nprint(\"%s: %.4f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}